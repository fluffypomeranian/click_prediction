summary(tree.local.train.c20)
plot(tree.local.train.c20)
text(tree.local.train.c20,pretty=0)
str(new_table)
hist(new_table$confidence_level)
hist(new_table$clicked)
hist(new_table$display_id)
hist(new_table$ad_id)
hist(new_table$document_id)
hist(new_table$topic_id)
attach(new_table)
confidence20=ifelse(new_table$confidence_level>=0.2,"Yes","No")
str(confidence20)
new_table=data.frame(new_table, confidence20)
tree.local.train.c20=tree(confidence20~.-new_table$confidence_level,data=new_table)
summary(tree.local.train.c20)
plot(tree.local.train.c20)
text(tree.local.train.c20,pretty=0)
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
#set.seed(123) ## set the seed to make your partition reproductible
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# list the structure of mydata
str(local_test_set)
# SET UP DATABASE CONNECTION
require("RPostgreSQL")    #install.packages("RPostgreSQL")
driver <- dbDriver("PostgreSQL")   # loads the PostgreSQL driver
# creates a connection to the postgres database
# note that "con" will be used later in each connection to the database
connection <- dbConnect(driver, dbname = "clickprediction",
host = "localhost", port = 5432,
user = "admin", password = "admin")
# confirm the tables are accessible
dbExistsTable(connection, "clicks_train")
# QUERY THE DATABASE
# 1)
# try to find features related to ad_id.
# here we join click_train and promoted-content with ad_id.
# look at clicks_train first
getClicksTrain="select * from clicks_train limit 10 "
clicks_train = dbGetQuery(connection, getClicksTrain)
clicks_train
# look at promoted_content next
getPromotedContent="select * from promoted_content limit 10"
promoted_content = dbGetQuery(connection, getPromotedContent)
promoted_content
# join click_train and promoted-content with ad_id new table
# 500k apears to be stable with rstudio.
join_query = "
select t.display_id, t.ad_id, t.clicked, d.document_id,
d.topic_id, d.confidence_level
from clicks_train t, promoted_content p, documents_topics d
where t.ad_id = p.ad_id and p.document_id = d.document_id
limit 500000;"
merged_table=dbGetQuery(connection, join_query)
head(merged_table, 3)
dim(merged_table)
# CREATE AND WRITE NEW TABLE
dbWriteTable(connection, "merged_table", merged_table, row.names=FALSE)
# look at the new table
getMergedTable="select * from merged_table limit 500000"
new_table = dbGetQuery(connection, getMergedTable)
# list the structure of mydata
str(new_table)
# CREATE DECISION TREE MODEL
require(tree)
str(new_table)
hist(new_table$confidence_level)
hist(new_table$clicked)
hist(new_table$display_id)
hist(new_table$ad_id)
hist(new_table$document_id)
hist(new_table$topic_id)
attach(new_table)
confidence20=ifelse(new_table$confidence_level>=0.2,"Yes","No")
str(confidence20)
new_table=data.frame(new_table, confidence20)
tree.local.train.c20=tree(confidence20~.-new_table$confidence_level,data=new_table)
summary(tree.local.train.c20)
plot(tree.local.train.c20)
text(tree.local.train.c20,pretty=0)
# CREATE TRAINING SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# list the structure of mydata
str(local_test_set)
# print first 10 rows of mydata
head(mydata, n=10)
# CREATE TRAINING SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# list the structure of mydata
str(local_test_set)
# print first 10 rows of mydata
head(local_test_set, n=10)
# SETUP
library(knitr)
library(markdown)
#transform the .Rmd to a markdown (.md) file.
knit('tims_script.Rmd')
# QUERY THE DATABASE
# 1)
# try to find features related to ad_id.
# here we join click_train and promoted-content with ad_id.
# look at clicks_train first
getClicksTrain="select * from clicks_train limit 10 "
clicks_train = dbGetQuery(connection, getClicksTrain)
clicks_train
# look at promoted_content next
getPromotedContent="select * from promoted_content limit 10"
promoted_content = dbGetQuery(connection, getPromotedContent)
promoted_content
# join click_train and promoted-content with ad_id new table
# 500k apears to be stable with rstudio.
join_query = "
select t.display_id, t.ad_id, t.clicked, d.document_id,
d.topic_id, d.confidence_level
from clicks_train t, promoted_content p, documents_topics d
where t.ad_id = p.ad_id and p.document_id = d.document_id
limit 500000;"
merged_table=dbGetQuery(connection, join_query)
head(merged_table, 3)
dim(merged_table)
# CREATE DECISION TREE MODEL
require(tree)
str(new_table)
hist(new_table$confidence_level)
hist(new_table$clicked)
hist(new_table$display_id)
hist(new_table$ad_id)
hist(new_table$document_id)
hist(new_table$topic_id)
attach(new_table)
confidence20=ifelse(new_table$confidence_level>=0.2,"Yes","No")
str(confidence20)
new_table=data.frame(new_table, confidence20)
tree.local.train.c20=tree(confidence20~.-new_table$confidence_level,data=new_table)
summary(tree.local.train.c20)
plot(tree.local.train.c20)
text(tree.local.train.c20,pretty=0)
# QUERY THE DATABASE
# 1)
# try to find features related to ad_id.
# here we join click_train and promoted-content with ad_id.
# look at clicks_train first
getClicksTrain="select * from clicks_train limit 10 "
clicks_train = dbGetQuery(connection, getClicksTrain)
clicks_train
# look at promoted_content next
getPromotedContent="select * from promoted_content limit 10"
promoted_content = dbGetQuery(connection, getPromotedContent)
promoted_content
# join click_train and promoted-content with ad_id new table
# 500k apears to be stable with rstudio.
join_query = "
select t.display_id, t.ad_id, t.clicked, d.document_id,
d.topic_id, d.confidence_level
from clicks_train t, promoted_content p, documents_topics d
where t.ad_id = p.ad_id and p.document_id = d.document_id
limit 500000;"
merged_table=dbGetQuery(connection, join_query)
head(merged_table, 3)
dim(merged_table)
# CREATE AND WRITE NEW TABLE
dbWriteTable(connection, "merged_table", merged_table, row.names=FALSE)
# look at the new table
getMergedTable="select * from merged_table limit 500000"
new_table = dbGetQuery(connection, getMergedTable)
# list the structure of mydata
str(new_table)
hist(new_table$clicked)
length(new_table$clicked[new_table$clicked>0])
install.packages("e1071")
library(e1071)
skewness(atteibute)
skewness(new_table$clicked)
?sample
# CREATE DECISION TREE MODEL
require(tree)
str(new_table)
hist(new_table$confidence_level)
hist(new_table$clicked)
hist(new_table$display_id)
hist(new_table$ad_id)
hist(new_table$document_id)
hist(new_table$topic_id)
attach(new_table)
confidence20=ifelse(new_table$confidence_level>=0.2,"Yes","No")
str(confidence20)
new_table=data.frame(new_table, confidence20)
tree.local.train.c20=tree(confidence20~.-new_table$confidence_level,data=new_table)
summary(tree.local.train.c20)
plot(tree.local.train.c20)
text(tree.local.train.c20,pretty=0)
# CREATE TRAINING SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# list the structure of mydata
str(local_test_set)
# print first 10 rows of mydata
head(local_test_set, n=10)
# CREATE TRAINING AND TEST SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
str(local_test_set)
# LOCAL TEST SET
head(local_test_set, n=10)
# LOCAL TRAIN SET
str(local_train_set)
# LOCAL TRAIN SET
head(local_train_set, n=10)
# CREATE TRAINING AND TEST SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
#str(local_test_set)
# LOCAL TEST SET
head(local_test_set, n=10)
# LOCAL TRAIN SET
#str(local_train_set)
# LOCAL TRAIN SET
head(local_train_set, n=10)
# CREATE TRAINING AND TEST SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
#str(local_test_set)
# LOCAL TEST SET
head(local_test_set, n=5)
# LOCAL TRAIN SET
#str(local_train_set)
# LOCAL TRAIN SET
head(local_train_set, n=5)
# CREATE TRAINING AND TEST SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
#str(local_test_set)
# LOCAL TEST SET
dim(local_test_set)
head(local_test_set, n=5)
# LOCAL TRAIN SET
#str(local_train_set)
# LOCAL TRAIN SET
dim(local_train_set)
head(local_train_set, n=5)
# CREATE TRAINING AND TEST SET
# list the structure of mydata
str(new_table)
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
str(partition_size)
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
dim(local_test_set)
head(local_test_set, n=5)
# LOCAL TRAIN SET
dim(local_train_set)
head(local_train_set, n=5)
?sample
ones = new_table$clicked = 1
zeros = sample(new_table$clicked=0, 50000)
zeros = new_table$clicked = 0
ones
zeros
ones = sample(new_table$clicked=1, 50000)
ones = sample(new_table$clicked[new_table$clicked=1], 50000)
ones = sample(new_table$clicked[new_table$clicked>0], 50000)
dim(new_table$clicked=1)
length(new_table$clicked[new_table$clicked>0])
# CREATE AND WRITE NEW TABLE
dbWriteTable(connection, "merged_table", merged_table, row.names=FALSE)
# look at the new table
getMergedTable="select * from merged_table limit 500000"
new_table = dbGetQuery(connection, getMergedTable)
# list the structure of mydata
str(new_table)
length(new_table$clicked[new_table$clicked>0])
# CREATE AND WRITE NEW TABLE
dbWriteTable(connection, "merged_table", merged_table, row.names=FALSE)
# look at the new table
getMergedTable="select * from merged_table limit 500000"
new_table = dbGetQuery(connection, getMergedTable)
# list the structure of mydata
str(new_table)
length(new_table$clicked[new_table$clicked>0])
length(new_table$clicked[new_table$clicked>0])
# QUERY THE DATABASE
# 1)
# try to find features related to ad_id.
# here we join click_train and promoted-content with ad_id.
# look at clicks_train first
getClicksTrain="select * from clicks_train limit 10 "
clicks_train = dbGetQuery(connection, getClicksTrain)
clicks_train
# look at promoted_content next
getPromotedContent="select * from promoted_content limit 10"
promoted_content = dbGetQuery(connection, getPromotedContent)
promoted_content
# join click_train and promoted-content with ad_id new table
# 500k apears to be stable with rstudio.
join_query = "
select t.display_id, t.ad_id, t.clicked, d.document_id,
d.topic_id, d.confidence_level
from clicks_train t, promoted_content p, documents_topics d
where t.ad_id = p.ad_id and p.document_id = d.document_id
limit 500000;"
merged_table=dbGetQuery(connection, join_query)
head(merged_table, 3)
dim(merged_table)
length(new_table$clicked[new_table$clicked>0])
# CREATE AND WRITE NEW TABLE
dbWriteTable(connection, "merged_table", merged_table, row.names=FALSE)
# look at the new table
getMergedTable="select * from merged_table limit 500000"
new_table = dbGetQuery(connection, getMergedTable)
# list the structure of mydata
str(new_table)
new_table = dbGetQuery(connection, getMergedTable)
# SET UP DATABASE CONNECTION
require("RPostgreSQL")    #install.packages("RPostgreSQL")
driver <- dbDriver("PostgreSQL")   # loads the PostgreSQL driver
# creates a connection to the postgres database
# note that "con" will be used later in each connection to the database
connection <- dbConnect(driver, dbname = "clickprediction",
host = "localhost", port = 5432,
user = "admin", password = "admin")
# confirm the tables are accessible
dbExistsTable(connection, "clicks_train")
# CREATE TRAINING AND TEST SET
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
dim(local_test_set)
head(local_test_set, n=5)
# LOCAL TRAIN SET
dim(local_train_set)
head(local_train_set, n=5)
# GET 50/50 CLICKED
#better:
#keep all the 1 instances from new_table
#ones <— new_table$clicked > 0
# zeros <— sample(new_table where $clicked = 0, 50000, … )
# create one data frame with zeros then append the ones
ones = sample(new_table$clicked[new_table$clicked>0], 50000)
zeros = new_table$clicked = 0
ones
zeros
zeros = sample(new_table$clicked=0, 50000)
length(new_table$clicked[new_table$clicked>0])
dim(new_table$clicked>0)
new_table = dbGetQuery(connection, getMergedTable)
length(new_table$clicked[new_table$clicked>0])
ones = new_table[new_table$clicked>0]
ones = new_table[new_table$clicked>0, ]
length(ones)
ones = new_table[new_table$clicked>0, 50000]
length(ones)
sample(new_table$clicked[new_table$clicked>0], 50000)
sample(new_table$clicked[new_table$clicked>0], 50000, replace=true)
onesVersion2 = ones = subset(new_table, clicked>0)
length(onesVersion2)
length(new_table$clicked[new_table$clicked>0])
# GET 50/50 CLICKED
#better:
#keep all the 1 instances from new_table
#ones <— new_table$clicked > 0
# zeros <— sample(new_table where $clicked = 0, 50000, … )
# create one data frame with zeros then append the ones
ones = new_table[new_table$clicked>0, 50000]
length(ones)
onesVersion2 = ones = subset(new_table, clicked>0)
length(onesVersion2)
zeros = sample(new_table$clicked=0, 50000)
length(new_table$clicked[new_table$clicked>0])
dim(new_table$clicked>0)
# QUERY THE DATABASE
# 1)
# try to find features related to ad_id.
# here we join click_train and promoted-content with ad_id.
# look at clicks_train first
getClicksTrain="select * from clicks_train limit 10 "
clicks_train = dbGetQuery(connection, getClicksTrain)
clicks_train
# look at promoted_content next
getPromotedContent="select * from promoted_content limit 10"
promoted_content = dbGetQuery(connection, getPromotedContent)
promoted_content
# join click_train and promoted-content with ad_id new table
# 500k apears to be stable with rstudio.
join_query = "
select t.display_id, t.ad_id, t.clicked, d.document_id,
d.topic_id, d.confidence_level
from clicks_train t, promoted_content p, documents_topics d
where t.ad_id = p.ad_id and p.document_id = d.document_id
limit 500000;"
merged_table=dbGetQuery(connection, join_query)
head(merged_table, 3)
dim(merged_table)
# CREATE AND WRITE NEW TABLE
dbWriteTable(connection, "merged_table", merged_table, row.names=FALSE)
# look at the new table
getMergedTable="select * from merged_table limit 500000"
new_table = dbGetQuery(connection, getMergedTable)
# list the structure of mydata
str(new_table)
# CREATE TRAINING AND TEST SET
partition_size = floor(0.80 * nrow(new_table)) ## 80% of the sample size
set.seed(123) ## set the seed to make your partition reproductible
partition_index <- sample(seq_len(nrow(new_table)), size = partition_size)
local_train_set <- new_table[partition_index, ]
local_test_set <- new_table[-partition_index, ]
# LOCAL TEST SET
dim(local_test_set)
head(local_test_set, n=5)
# LOCAL TRAIN SET
dim(local_train_set)
head(local_train_set, n=5)
ones = new_table[new_table$clicked>0, 50000]
length(ones)
length(new_table)
table(new_table$clicked)
onesVersion2 = ones = subset(new_table, clicked>0)
dim(onesVersion2)
zeros = sample(new_table$clicked=0, 50000)
zeros = sample(new_table$clicked<1, 50000)
dim(zeros)
zeros = subset(new_table, clicked = 0)
dim(zeros)
undersampled_zeros =apply(zeros, 1, sample, 50000)
zeros = subset(new_table, clicked > 1)
zeros = subset(new_table, clicked < 1)
#zeros = sample(new_table$clicked<1, 50000)
dim(zeros)
undersampled_zeros =apply(zeros, 1, sample, 50000)
undersampled_zeros =apply(zeros, 1, sample, 450014)
undersampled_zeros =apply(zeros, 1, sample, 450013)
undersampled_zeros =apply(zeros, 50000, sample, 1)
undersampled_zeros =apply(zeros, 50000, sample, 1)
table(zeros)
table(zeros$clicked)
table(ones$clicked)
undersampled_zeros = new_table[sample(nrow(new_table), 50000), ]
table(zeros$clicked)
table(ones$clicked)
table(undersampled_zeros$clicked)
undersampled_zeros = zeros[sample(nrow(zeros), 50000), ]
table(undersampled_zeros$clicked)
table(ones$clicked)
dim(undersampled_zeros)
dim(ones)
names(undersampled_zeros)
names(ones)
final_dataset<- data.frame(ones, undersampled_zeros )
final_dataset <- merge(undersampled_zeros, ones )
dim(final_dataset)
final_dataset <- merge(undersampled_zeros, ones, all.x=TRUE)
dim(final_dataset)
final_dataset <- merge(undersampled_zeros, ones, all.x=TRUE, all.y=TRUE)
dim(final_dataset)
